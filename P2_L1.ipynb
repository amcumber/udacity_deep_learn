{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project 2: Lesson 1: Intro to NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.Path('assets/p2_l1_m11/data.csv')\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(f, header=None)\n",
    "X = df.iloc[:,:2].values\n",
    "y = df.iloc[:, -1].values\n",
    "W = np.array(np.random.rand(2,1))\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0]) ##FIXME it doesn't like starts - maybe a for loop like a pleb\n",
    "#     return np.array([*map(stepFunction, np.matmul(X,W)+b)])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate=0.01):\n",
    "    # Fill in code\n",
    "    for i in range(X.shape[0]):\n",
    "        alpha_i = (y[i] - prediction(X[i,:], W, b)) * learn_rate\n",
    "        W[:, 0] += X[i, :] * alpha_i\n",
    "        b += alpha_i\n",
    "    return W, b\n",
    "\n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT / Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-0.05239463]), array([-2.04919443])),\n",
       " (array([1.23772563]), array([-2.90815949])),\n",
       " (array([-39.47663703]), array([23.57864461])),\n",
       " (array([-13.13237331]), array([7.06473087])),\n",
       " (array([-9.11612538]), array([4.57527519])),\n",
       " (array([-7.79056954]), array([3.96940892])),\n",
       " (array([-6.7750263]), array([3.50523881])),\n",
       " (array([-5.97212608]), array([3.13826056])),\n",
       " (array([-5.32141098]), array([2.84084093])),\n",
       " (array([-4.78335796]), array([2.59491529])),\n",
       " (array([-4.33103935]), array([2.38817591])),\n",
       " (array([-4.09146109]), array([2.3928177])),\n",
       " (array([-3.80251597]), array([2.25914697])),\n",
       " (array([-3.54414571]), array([2.13962066])),\n",
       " (array([-3.31174122]), array([2.03210655])),\n",
       " (array([-3.10157551]), array([1.93488045])),\n",
       " (array([-2.91060228]), array([1.84653311])),\n",
       " (array([-2.73630733]), array([1.76590142])),\n",
       " (array([-2.57659722]), array([1.69201691])),\n",
       " (array([-2.4297148]), array([1.6240667])),\n",
       " (array([-2.29417429]), array([1.56136344])),\n",
       " (array([-2.16871083]), array([1.50332199])),\n",
       " (array([-2.05224089]), array([1.4494411])),\n",
       " (array([-1.94383093]), array([1.39928887])),\n",
       " (array([-1.84267226]), array([1.35249122]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPerceptronAlgorithm(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrete vs Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def wrap_score(func):\n",
    "    @wraps(func)\n",
    "    def score_wrap(X: 'n,2 array'):\n",
    "        score = np.array([4,5]).dot(X.T) - 9\n",
    "        return func(score)\n",
    "    return score_wrap\n",
    "\n",
    "# def score(X: 'n,2 array'):\n",
    "#     return np.array([4,5]).dot(X.T) - 9\n",
    "\n",
    "def sigmoid(score):\n",
    "    return (1+np.exp(-score)) ** -1\n",
    "\n",
    "@wrap_score\n",
    "def my_score(X: 'n,2 array'):\n",
    "    return (1+np.exp(-X)) ** -1\n",
    "\n",
    "def softmax(L: list(int)):\n",
    "    sum_e =  sum([np.exp(i) for i in L])\n",
    "    return [np.exp(zi)  / sum_e for zi in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0020328 , 0.00167195, 0.00153523, 0.0032615 , 0.00548455,\n",
       "       0.00064314, 0.0019504 , 0.00340945, 0.00403575, 0.00109842,\n",
       "       0.00025264, 0.00108674, 0.00289163, 0.00581028, 0.00694841,\n",
       "       0.00182312, 0.00261146, 0.00142696, 0.00554212, 0.00326459,\n",
       "       0.00469342, 0.00536489, 0.00861772, 0.00091614, 0.01288949,\n",
       "       0.01303598, 0.0039543 , 0.00095297, 0.00061713, 0.00441418,\n",
       "       0.00169914, 0.0007363 , 0.00454257, 0.01459218, 0.00192451,\n",
       "       0.00123074, 0.01816405, 0.00569192, 0.00544401, 0.00315109,\n",
       "       0.00377433, 0.0259986 , 0.00081322, 0.01437111, 0.0002509 ,\n",
       "       0.00067115, 0.00676483, 0.0052026 , 0.0010781 , 0.00297367,\n",
       "       0.1434655 , 0.01380545, 0.0922087 , 0.0951504 , 0.02072991,\n",
       "       0.23880359, 0.11640328, 0.08270341, 0.05017742, 0.09043624,\n",
       "       0.01320926, 0.10627291, 0.03776958, 0.06196311, 0.04812142,\n",
       "       0.08560022, 0.02846201, 0.01456818, 0.01566604, 0.12319134,\n",
       "       0.2096958 , 0.0395548 , 0.14932183, 0.04618653, 0.02725752,\n",
       "       0.13331741, 0.08146474, 0.07619818, 0.04598694, 0.04463821,\n",
       "       0.04639048, 0.05807885, 0.07867916, 0.02967028, 0.00779583,\n",
       "       0.11320937, 0.02139041, 0.12723062, 0.06324297, 0.11054561,\n",
       "       0.19029877, 0.05423898, 0.04986428, 0.09171685, 0.08719303,\n",
       "       0.08227428, 0.07694059, 0.01314852, 0.21591206, 0.02176238])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_score(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000000e-01, 9.99999994e-01, 8.31528028e-07, 5.00000000e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_score(np.array([(1, 1), \n",
    "                   (2, 4), \n",
    "                   (5, -5),\n",
    "                   (-4, 5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09003057317038046, 0.24472847105479764, 0.6652409557748219]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.881784197001252e-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.array(Y)\n",
    "    P = np.array(P)\n",
    "    return Y.dot(-np.log(P.T))  + (1-Y).dot(-np.log((1-P).T))\n",
    "\n",
    "\n",
    "def test_ce():\n",
    "    Y = [0, 1, 0]\n",
    "    P = [0.9, 0.2, 0.1]\n",
    "    expected = -sum([np.log(0.1), np.log(0.2), np.log(0.9)])\n",
    "    return expected - cross_entropy(Y, P)\n",
    "\n",
    "test_ce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.88 = w1 * 0.4 + w2 * 0.6 + b\n",
    "x = np.array([[0.4, 0.6, 1]])\n",
    "# w . x = y\n",
    "# w . (x.x) = (y.x)\n",
    "# w . (x.x) - y.x = 0\n",
    "# (w . (x) - y) = 0\n",
    "# w-1.w.x = w-1.y\n",
    "# I.x = w-1.y\n",
    "# x = w-1.y\n",
    "# need to recall multi-var..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_results(func):\n",
    "    @wraps(func)\n",
    "    def sigmoid(*args, **kwargs):\n",
    "        returned = func(*args, **kwargs)\n",
    "        return (1+np.exp(-returned)) ** -1\n",
    "    return sigmoid\n",
    "\n",
    "@sigmoid_results\n",
    "def f(w1, w2, b):\n",
    "    x = np.array([0.4, 0.6, 1])\n",
    "    return np.array([w1,w2, b]).dot(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168273035060777\n",
      "0.8807970779778823\n",
      "0.8021838885585818\n"
     ]
    }
   ],
   "source": [
    "# Search for 88% return\n",
    "[print(x) for x in map(lambda w: f(*w), [(2, 6, -2), (3, 5, -2.2), (5, 4, -3)])];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
